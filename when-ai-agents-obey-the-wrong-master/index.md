# When AI Agents Obey The Wrong Master

A talk by **Niv Rabin**

---

## ğŸ“– About This Talk

AI agents are designed to plan, persist, and act autonomously using LLMs, memory, tool calling, and external data retrieval. But what happens when these same capabilities become their greatest weakness?

In this talk, we walk through a series of real-world attacks that caused our AI agent to go off-script - executing actions it was never intended to take. These weren't theoretical threats; they were working prompt injection attacks, hidden in plain sight across user inputs and API responses. Early attempts at mitigation failed to catch the problem until it was too late, highlighting just how difficult these attacks are to detect in agent-based systems.

Through live-inspired demos, we showcase the escalating nature of these threats - from basic manipulations to sophisticated multi-step exploits. More importantly, we share the turning point: a multi-layered defense strategy that combines input detection, retrieval sanitization, and honeypot tools to proactively defend agents without compromising functionality.

Whether you're building agents or securing them, this session will leave you with a practical understanding of how real-world attacks unfold - and how to stop them before your agents obey the wrong master.

---

## ğŸ”— Connect

- [LinkedIn Profile](https://www.linkedin.com/in/nivmorabin/)

---

## ğŸ“ Talk Resources

### Blog Post

ğŸš§ *Coming Soon*

---

## ğŸ›¡ï¸ Mitigation Strategies

- [Blog Post: Securing LLM Applications â€“ Where Content Safeguards Meet LLMs as Judges](https://medium.com/cyberark-engineering/securing-llm-applications-where-content-safeguards-meet-llms-as-judges-c3d4a851eddb)
- [Notebook: LLM Attacks Detection Methods Evaluation](https://github.com/cyberark/FuzzyAI/blob/main/src/fuzzyai/resources/notebooks/llm_attacks_detection_methods_evaluation/notebook.ipynb)

---

## ğŸ¯ Honeypots

Leveraging LLM function calling as a defense mechanism:

- [English: Catching the Uninvited â€“ Leveraging the LLM Function Calling Mechanism as a Seamless Defense Layer](https://medium.com/cyberark-engineering/catching-the-uninvited-leveraging-the-llm-function-calling-mechanism-as-a-seamless-defense-layer-98ca07028ce2)
- [Hebrew: Function Calling and Honeypots (Geektime)](https://www.geektime.co.il/function-calling-and-honeypots/)

---

## ğŸ”§ Tools

- [FuzzyAI Repository](https://github.com/cyberark/FuzzyAI) â€“ Fuzzing framework for AI/LLM security testing

